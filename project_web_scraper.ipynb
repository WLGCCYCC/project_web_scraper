{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########Import Modules#########\n",
    "import requests\n",
    "from math import ceil\n",
    "from bs4 import BeautifulSoup\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######Start Up Function#########\n",
    "def inform_input():\n",
    "    global f_type\n",
    "    global f_city\n",
    "    global f_state\n",
    "\n",
    "    correct_input = False\n",
    "\n",
    "    while correct_input != True:\n",
    "\n",
    "        f_type = input('What type of firms do you want to search? (example: asset management)\\nFirm type: ')\n",
    "        print ('\\n')\n",
    "\n",
    "        f_city = input(\"Which city do you want to search? (example: Los Angeles)\\nHint: If you want to search an entire state, then type 'ALL.'\\nCity: \")\n",
    "        print ('\\n')\n",
    "\n",
    "        f_state = input('Which state do you want to search? (example: CA)\\nState: ')\n",
    "        print ('\\n')\n",
    "\n",
    "        print ('Searching...'+f_type+' in '+f_city+','+f_state+'.\\n')\n",
    "        correct_input = input('Is the key words correct? [Y/N]\\nAnswer: ')\n",
    "        print ('\\n')\n",
    "\n",
    "        if correct_input.upper() == 'Y':\n",
    "            correct_input = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url(firm_type,firm_city,firm_state):\n",
    "    \n",
    "    print ('creating url......')\n",
    "    \n",
    "    firm_type = firm_type.lower()\n",
    "    firm_city = firm_city.lower()\n",
    "    firm_state = firm_state.upper()\n",
    "\n",
    "    firm_type = firm_type.split()\n",
    "    firm_city = firm_city.split()\n",
    "\n",
    "    ##basic form of url'https://www.yellowpages.com/search?search_terms=asset%20management&geo_location_terms=los%20angeles%2C%20CA&page=1'\n",
    "\n",
    "    url = 'https://www.yellowpages.com/search?search_terms='\n",
    "\n",
    "    url += firm_type.pop(0)\n",
    "    while len(firm_type)!=0:\n",
    "        url += '%20'+firm_type.pop(0)\n",
    "\n",
    "    url += '&geo_location_terms='\n",
    "\n",
    "    url += firm_city.pop(0)\n",
    "    while len(firm_city)!=0:\n",
    "        url += '%20'+firm_city.pop(0)\n",
    "    \n",
    "    url += '%2C%20'+firm_state+'&page='\n",
    "    \n",
    "    print ('creating url......done!')\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_number(soup):\n",
    "    \n",
    "    print ('finding total page number......')\n",
    "    total_results = soup.find_all('div',{\"class\":\"pagination\"})\n",
    "\n",
    "    total_results = total_results[0].contents[0].text\n",
    "\n",
    "\n",
    "    total_results = total_results.split()\n",
    "\n",
    "    total_results = total_results.pop()\n",
    "\n",
    "    total_results = int(total_results.replace('results',''))\n",
    "    \n",
    "    print ('finding total page number......'+str(ceil(total_results/30)))\n",
    "\n",
    "    return ceil(total_results/30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contact_inform(url):\n",
    "    \n",
    "    global firm_name\n",
    "    global firm_adr\n",
    "    global firm_web\n",
    "    global firm_phone\n",
    "    r = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "    g_data = soup.find_all('div', {'class':'info'})\n",
    "    ######################get name#################\n",
    "    for item in g_data:\n",
    "        try:\n",
    "            firm_name.append(str(item.contents[0].find_all('a',{'class':'business-name'})[0].text))\n",
    "        except:\n",
    "            firm_name.append('N/A')\n",
    "\n",
    "    ######################get address#################\n",
    "    for item in g_data:\n",
    "        try:\n",
    "            address = ''\n",
    "            address += str(item.contents[1].find_all('span',{'class':'street-address'})[0].text) + ','\n",
    "            address += str(item.contents[1].find_all('span',{'itemprop':'addressLocality'})[0].text).replace('\\xa0','')\n",
    "            address += str(item.contents[1].find_all('span',{'itemprop':'addressRegion'})[0].text) + ','\n",
    "            address += str(item.contents[1].find_all('span',{'itemprop':'postalCode'})[0].text)\n",
    "\n",
    "            firm_adr.append(address)\n",
    "        except:\n",
    "            firm_adr.append('N/A')\n",
    "\n",
    "    ####################get phone number###################\n",
    "    for item in g_data:\n",
    "        try:\n",
    "            firm_phone.append(str(item.contents[1].find_all('div',{'itemprop':'telephone'})[0].text))\n",
    "        except:\n",
    "            firm_phone.append('N/A')\n",
    "\n",
    "    ####################get website###################\n",
    "    for item in g_data:\n",
    "        try:\n",
    "            firm_web.append(str(item.contents[2].find_all('a',{'class':'track-visit-website'})[0].get('href')))\n",
    "        except:\n",
    "            firm_web.append('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_city_list(s):\n",
    "    from city_to_state import city_to_state_dict as c_to_s\n",
    "\n",
    "    from abbrev_to_state import states as s_to_a\n",
    "\n",
    "    city_list = []\n",
    "\n",
    "\n",
    "    for city, state in c_to_s.items():\n",
    "        if state  == s_to_a[s.upper()]:\n",
    "             city_list.append(city)\n",
    "    \n",
    "    \n",
    "    return city_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def del_dup_elements():\n",
    "    \n",
    "    print(\"deleting duplicated information......\")\n",
    "    \n",
    "    global firm_name\n",
    "    global firm_adr\n",
    "    global firm_web\n",
    "    global firm_phone\n",
    "    \n",
    "    index_dup = []\n",
    "\n",
    "    for i in range(len(firm_adr) - 1):\n",
    "\n",
    "        for j in range(i+1,len(firm_adr)):\n",
    "\n",
    "            if firm_adr[j] == firm_adr[i]:\n",
    "                if firm_name[j] == firm_name[i]:\n",
    "                    if firm_phone[j] == firm_phone[i]:\n",
    "                        if firm_web[j] == firm_web[i]: \n",
    "                            index_dup.append(i)\n",
    "                            break\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(index_dup)):\n",
    "\n",
    "\n",
    "        firm_adr.pop(index_dup[i])\n",
    "        firm_name.pop(index_dup[i])\n",
    "        firm_phone.pop(index_dup[i])\n",
    "        firm_web.pop(index_dup[i])\n",
    "        index_dup =  list(map(lambda x :x-1,index_dup)) \n",
    "    \n",
    "    print(\"deleting duplicated information......done!\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_xlsx_file():\n",
    "    global firm_name\n",
    "    global firm_adr\n",
    "    global firm_web\n",
    "    global firm_phone\n",
    "    print('writing xlsx file......')\n",
    "\n",
    "    workbook = xlsxwriter.Workbook('Contact Information-%s in %s,%s.xlsx'%(f_type,f_city,f_state))\n",
    "\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    bold = workbook.add_format({'bold':1,'bg_color':'lime','bottom':1})\n",
    "\n",
    "    worksheet.write('A1','Firm',bold)\n",
    "    worksheet.write('B1','Address',bold)\n",
    "    worksheet.write('C1','Website',bold)\n",
    "    worksheet.write('D1','Phone numer',bold)\n",
    "\n",
    "\n",
    "    row = 1\n",
    "    col = 0\n",
    "    for variable in [firm_name,firm_adr,firm_web,firm_phone]:\n",
    "        for element in variable:\n",
    "\n",
    "            worksheet.write_string(row,col,element)\n",
    "            row +=1\n",
    "        maxlen = max(list(map(len,variable)))    \n",
    "        worksheet.set_column(col, col, maxlen)\n",
    "\n",
    "        row = 1\n",
    "        col += 1\n",
    "\n",
    "\n",
    "    workbook.close()\n",
    "\n",
    "    print('writing xlsx file......done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################main function##################\n",
    "print ('-------------Program start--------------')\n",
    "\n",
    "print ('Hello! This is a web scraper program that automatically collects the contact information of firms within a region.\\n')\n",
    "\n",
    "print ('Note: This program will use public data from yellowpages.com\\n')\n",
    "\n",
    "firm_name = []\n",
    "firm_adr = []\n",
    "firm_web = []\n",
    "firm_phone = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_type = ''\n",
    "f_city = ''\n",
    "f_state = ''\n",
    "\n",
    "while True:\n",
    "\n",
    "    inform_input()\n",
    "\n",
    "    if f_city.lower() != 'all':\n",
    "        url_base = get_url(f_type,f_city,f_state)\n",
    "\n",
    "        r = requests.get(url_base+'3')\n",
    "\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "        page_number = get_page_number(soup)\n",
    "\n",
    "        for number in range(1,page_number+1):\n",
    "\n",
    "            url = url_base + str(number)\n",
    "            get_contact_inform(url)\n",
    "            print ('collecting information from page ' + str(number) + ' out of ' + str(page_number) + '......')\n",
    "\n",
    "        print ('All the information is collected successfully!\\n')\n",
    "        \n",
    "        \n",
    "    else :\n",
    "        print (\"searching for all cities in \" + str(f_state))\n",
    "        c_list = get_city_list(f_state)\n",
    "        for city in c_list:\n",
    "            print ('\\nSearching...'+f_type+' in '+city+','+f_state+'.\\n')\n",
    "            \n",
    "            url_base = get_url(f_type,city,f_state)\n",
    "\n",
    "            r = requests.get(url_base+'3')\n",
    "\n",
    "            soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "            page_number = get_page_number(soup)\n",
    "\n",
    "            for number in range(1,page_number+1):\n",
    "\n",
    "                url = url_base + str(number)\n",
    "                get_contact_inform(url)\n",
    "                print ('collecting information from page ' + str(number) + ' out of ' + str(page_number) + '......')\n",
    "\n",
    "        print ('All the information is collected successfully!\\n')\n",
    "            \n",
    "        \n",
    "    \n",
    "    repeat = input (\"Do you want to search for another city or type of firm? The results will be added to the list.(Y/N)\\nAnswer: \")\n",
    "    \n",
    "    if repeat.upper() != 'Y':\n",
    "        break\n",
    "\n",
    "del_dup_elements()\n",
    "\n",
    "write_xlsx_file()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
